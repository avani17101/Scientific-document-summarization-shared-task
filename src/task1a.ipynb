{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "848ada26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b17845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59ecf163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-29 15:10:41.943695: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:/usr/local/apps/cuDNN/7.6.5-cuda-10.2/lib64\n",
      "2021-11-29 15:10:41.943769: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import scipy\n",
    "import numpy as np\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d64406aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P83-1020',\n",
       " 'W02-1039',\n",
       " 'P96-1021',\n",
       " 'N06-1020',\n",
       " 'C86-1016',\n",
       " 'C92-2070',\n",
       " 'D08-1082',\n",
       " 'J01-2002',\n",
       " 'C02-1114',\n",
       " 'P85-1018',\n",
       " 'P07-1032',\n",
       " 'W00-1427',\n",
       " 'C04-1111',\n",
       " 'J97-1002',\n",
       " 'W04-3237',\n",
       " 'E87-1002',\n",
       " 'P93-1041',\n",
       " 'P90-1034',\n",
       " 'P98-1035',\n",
       " 'W02-0505',\n",
       " 'P13-1045',\n",
       " 'A00-2026',\n",
       " 'J03-4004',\n",
       " 'N03-1003',\n",
       " 'C90-2067',\n",
       " 'P84-1075',\n",
       " 'W02-0908',\n",
       " 'M95-1005',\n",
       " 'P07-1028',\n",
       " 'C00-2136',\n",
       " 'P01-1019',\n",
       " 'N10-1056',\n",
       " 'J81-4003',\n",
       " 'P93-1024',\n",
       " 'C90-3030',\n",
       " 'W02-2024',\n",
       " 'P98-1013',\n",
       " 'P03-1019',\n",
       " 'P07-1065',\n",
       " 'I05-3017',\n",
       " 'P07-1056',\n",
       " 'W03-0419',\n",
       " 'W00-0726',\n",
       " 'A00-2031',\n",
       " 'D07-1090',\n",
       " 'P02-1040',\n",
       " 'P05-1011',\n",
       " 'P02-1043',\n",
       " 'A00-2009',\n",
       " 'H94-1046',\n",
       " 'C00-1044',\n",
       " 'P11-1138',\n",
       " 'C02-1011',\n",
       " 'C96-1055',\n",
       " 'N06-2015',\n",
       " 'N03-1024',\n",
       " 'P08-1101',\n",
       " 'P96-1025',\n",
       " 'P02-1019',\n",
       " 'P09-1088',\n",
       " 'C94-1042',\n",
       " 'P99-1068',\n",
       " 'N07-1018',\n",
       " 'D07-1043',\n",
       " 'J93-1007',\n",
       " 'C08-1022',\n",
       " 'P01-1030',\n",
       " 'J01-2001',\n",
       " 'N01-1008',\n",
       " 'P05-3026',\n",
       " 'P96-1024',\n",
       " 'A00-2019',\n",
       " 'E06-1042',\n",
       " 'N06-1014',\n",
       " 'P03-1011',\n",
       " 'P11-1016',\n",
       " 'C92-2082',\n",
       " 'P02-1038',\n",
       " 'J01-4004',\n",
       " 'N09-1046',\n",
       " 'D11-1125',\n",
       " 'P94-1020',\n",
       " 'W04-2609',\n",
       " 'P09-1027',\n",
       " 'H05-1073',\n",
       " 'E06-1051',\n",
       " 'P00-1065',\n",
       " 'P04-1085',\n",
       " 'P02-1017',\n",
       " 'J91-1002',\n",
       " 'J00-3004',\n",
       " 'D09-1159',\n",
       " 'P08-1004',\n",
       " 'P02-1014',\n",
       " 'W04-3250',\n",
       " 'W02-1018',\n",
       " 'J00-4003',\n",
       " 'J03-3002',\n",
       " 'P00-1071',\n",
       " 'D07-1101',\n",
       " 'P84-1018',\n",
       " 'N09-1009',\n",
       " 'P02-1060',\n",
       " 'A97-1052',\n",
       " 'C00-2137',\n",
       " 'P05-1057',\n",
       " 'D08-1022',\n",
       " 'C92-3150',\n",
       " 'J92-1004',\n",
       " 'P06-1067',\n",
       " 'E06-1031',\n",
       " 'J04-4004',\n",
       " 'N06-1039',\n",
       " 'W02-2018',\n",
       " 'P07-1121',\n",
       " 'W04-0807',\n",
       " 'P87-1033',\n",
       " 'N03-2002',\n",
       " 'W02-1001',\n",
       " 'J05-1003',\n",
       " 'D08-1031',\n",
       " 'J93-2005',\n",
       " 'N01-1023',\n",
       " 'W03-0407',\n",
       " 'C04-1051',\n",
       " 'N04-1015',\n",
       " 'D10-1001',\n",
       " 'A00-1031',\n",
       " 'P08-2007',\n",
       " 'P09-1010',\n",
       " 'I08-1059',\n",
       " 'J00-4005',\n",
       " 'E99-1023',\n",
       " 'M95-1012',\n",
       " 'C94-2178',\n",
       " 'P08-1086',\n",
       " 'W04-3208',\n",
       " 'W03-1508',\n",
       " 'N06-1058',\n",
       " 'P01-1064',\n",
       " 'P88-1020',\n",
       " 'J02-2003',\n",
       " 'E06-1040',\n",
       " 'P07-1031',\n",
       " 'J07-3004',\n",
       " 'P02-1006',\n",
       " 'P02-1062',\n",
       " 'C94-2174',\n",
       " 'N06-1006',\n",
       " 'N09-1028',\n",
       " 'P90-1005',\n",
       " 'C04-1010',\n",
       " 'P03-1071',\n",
       " 'N04-1021',\n",
       " 'A94-1009',\n",
       " 'N01-1020',\n",
       " 'P08-1024',\n",
       " 'P09-1068',\n",
       " 'N07-1030',\n",
       " 'J86-3001',\n",
       " 'J03-1005',\n",
       " 'N04-3012',\n",
       " 'D12-1133',\n",
       " 'N12-1052',\n",
       " 'H05-1066',\n",
       " 'P07-1094',\n",
       " 'P08-1108',\n",
       " 'P04-1075',\n",
       " 'P93-1001',\n",
       " 'N04-1014',\n",
       " 'P11-1020',\n",
       " 'W04-3219',\n",
       " 'J93-1003',\n",
       " 'S10-1011',\n",
       " 'P96-1006',\n",
       " 'J93-2006',\n",
       " 'P95-1007',\n",
       " 'J94-2003',\n",
       " 'D07-1002',\n",
       " 'P09-1042',\n",
       " 'E99-1010',\n",
       " 'W03-1730',\n",
       " 'D09-1001',\n",
       " 'J94-4003',\n",
       " 'N03-1021',\n",
       " 'A94-1016',\n",
       " 'P93-1020',\n",
       " 'J02-1002',\n",
       " 'H94-1048',\n",
       " 'W03-0301',\n",
       " 'W04-0811',\n",
       " 'J94-4002',\n",
       " 'P97-1009',\n",
       " 'N04-4038',\n",
       " 'P04-1061',\n",
       " 'J03-3005',\n",
       " 'J91-1003',\n",
       " 'J90-1003',\n",
       " 'P99-1059',\n",
       " 'P00-1037',\n",
       " 'W04-3103',\n",
       " 'D10-1048',\n",
       " 'P08-1084',\n",
       " 'J96-1002',\n",
       " 'W01-0501',\n",
       " 'H05-1010',\n",
       " 'W03-0405',\n",
       " 'H92-1026',\n",
       " 'P04-1018',\n",
       " 'J97-3002',\n",
       " 'P01-1008',\n",
       " 'J96-1001',\n",
       " 'N03-1017',\n",
       " 'C04-1080',\n",
       " 'P07-1004',\n",
       " 'P05-1036',\n",
       " 'P91-1027',\n",
       " 'P03-1056',\n",
       " 'P93-1008',\n",
       " 'W03-1028',\n",
       " 'P04-1041',\n",
       " 'P97-1005',\n",
       " 'P06-1124',\n",
       " 'J98-2004',\n",
       " 'J92-4007',\n",
       " 'P92-1005',\n",
       " 'C96-2183',\n",
       " 'P94-1012',\n",
       " 'W00-1308',\n",
       " 'J98-4004',\n",
       " 'W03-1812',\n",
       " 'P09-1077',\n",
       " 'P91-1034',\n",
       " 'J87-1004',\n",
       " 'N04-1013',\n",
       " 'P02-1039',\n",
       " 'W02-0902',\n",
       " 'N09-1036',\n",
       " 'W03-0501',\n",
       " 'D08-1092',\n",
       " 'P98-1012',\n",
       " 'P07-1005',\n",
       " 'H05-1004',\n",
       " 'J92-4003',\n",
       " 'D08-1035',\n",
       " 'D07-1072',\n",
       " 'D07-1104',\n",
       " 'P91-1023',\n",
       " 'N04-4015',\n",
       " 'P02-1033',\n",
       " 'P98-2182',\n",
       " 'P89-1010',\n",
       " 'P03-1023',\n",
       " 'P03-1054',\n",
       " 'J03-1003',\n",
       " 'W04-2705',\n",
       " 'N03-1016',\n",
       " 'P02-1035',\n",
       " 'P07-1049',\n",
       " 'P03-1012',\n",
       " 'N06-1025',\n",
       " 'I05-2038',\n",
       " 'J04-2003',\n",
       " 'P08-1066',\n",
       " 'P05-1034',\n",
       " 'W04-3206',\n",
       " 'P97-1035',\n",
       " 'P06-1043',\n",
       " 'P07-1037',\n",
       " 'N06-1011',\n",
       " 'S10-1010',\n",
       " 'N12-1047',\n",
       " 'P07-1019',\n",
       " 'P06-2005',\n",
       " 'P03-1035',\n",
       " 'N09-2004',\n",
       " 'J06-1003',\n",
       " 'W03-1728',\n",
       " 'P97-1063',\n",
       " 'P06-1114',\n",
       " 'P07-1059',\n",
       " 'P07-1034',\n",
       " 'H93-1051',\n",
       " 'N01-1021',\n",
       " 'N03-1014',\n",
       " 'P99-1041',\n",
       " 'W03-1017',\n",
       " 'P08-2012',\n",
       " 'P95-1037',\n",
       " 'C10-2028',\n",
       " 'P03-1003',\n",
       " 'J99-2004',\n",
       " 'P05-1001',\n",
       " 'N09-1037',\n",
       " 'P87-1022',\n",
       " 'P99-1032',\n",
       " 'P89-1009',\n",
       " 'D08-1016',\n",
       " 'H91-1026',\n",
       " 'P92-1008',\n",
       " 'C04-1197',\n",
       " 'H05-1012',\n",
       " 'W00-0403',\n",
       " 'D07-1109',\n",
       " 'P05-1074',\n",
       " 'J93-1001',\n",
       " 'N07-1023',\n",
       " 'D07-1007',\n",
       " 'P01-1005',\n",
       " 'P96-1038',\n",
       " 'P04-1021',\n",
       " 'P95-1021',\n",
       " 'P93-1005',\n",
       " 'W00-0717',\n",
       " 'C94-1027',\n",
       " 'J93-1002',\n",
       " 'H05-1043',\n",
       " 'P98-1034',\n",
       " 'N04-1016',\n",
       " 'N06-1033',\n",
       " 'P04-1013',\n",
       " 'P01-1025',\n",
       " 'C90-3063',\n",
       " 'N01-1024',\n",
       " 'W04-2319',\n",
       " 'P03-2026',\n",
       " 'P07-1073',\n",
       " 'E06-1032',\n",
       " 'P03-1013',\n",
       " 'E06-1015',\n",
       " 'W03-0428',\n",
       " 'J99-1003',\n",
       " 'P05-1072',\n",
       " 'C86-1045',\n",
       " 'P06-2014',\n",
       " 'J01-3003',\n",
       " 'W04-1013',\n",
       " 'J05-1004',\n",
       " 'W03-1810',\n",
       " 'P09-2004',\n",
       " 'P96-1027',\n",
       " 'P00-1016',\n",
       " 'W04-3239',\n",
       " 'H05-1091',\n",
       " 'I05-3027',\n",
       " 'C94-2195',\n",
       " 'S12-1053',\n",
       " 'P11-2031',\n",
       " 'P08-1030',\n",
       " 'J02-3001',\n",
       " 'C90-3044',\n",
       " 'P06-1005',\n",
       " 'P06-1055',\n",
       " 'D11-1014',\n",
       " 'P05-1010',\n",
       " 'E03-1008',\n",
       " 'W04-3236',\n",
       " 'P10-1001',\n",
       " 'P03-1009',\n",
       " 'P99-1069',\n",
       " 'P02-1034',\n",
       " 'P05-1018',\n",
       " 'J80-3003',\n",
       " 'P05-1033',\n",
       " 'P06-1097',\n",
       " 'W04-3213',\n",
       " 'P99-1071',\n",
       " 'P08-1036',\n",
       " 'P05-1045',\n",
       " 'P99-1067',\n",
       " 'N10-1061',\n",
       " 'P07-1107',\n",
       " 'D08-1065',\n",
       " 'P98-1010',\n",
       " 'P06-1103',\n",
       " 'P05-2008',\n",
       " 'P05-1066',\n",
       " 'P02-1046',\n",
       " 'J10-3003',\n",
       " 'W03-0425',\n",
       " 'W02-1503',\n",
       " 'W04-3201',\n",
       " 'P98-2204',\n",
       " 'D08-1083',\n",
       " 'W01-0521',\n",
       " 'P06-1091',\n",
       " 'P88-1015',\n",
       " 'D09-1101',\n",
       " 'J98-1001',\n",
       " 'J90-1004',\n",
       " 'J10-4006',\n",
       " 'P02-1001',\n",
       " 'P00-1058',\n",
       " 'H93-1061',\n",
       " 'H05-1044',\n",
       " 'P05-1022',\n",
       " 'P08-1076',\n",
       " 'P94-1002',\n",
       " 'D11-1006',\n",
       " 'A00-2034',\n",
       " 'J08-1002',\n",
       " 'P08-1115',\n",
       " 'P09-1104',\n",
       " 'C02-1139',\n",
       " 'P98-1112',\n",
       " 'N06-2013',\n",
       " 'D08-1059',\n",
       " 'J97-3003',\n",
       " 'P09-1039',\n",
       " 'J09-3003',\n",
       " 'P06-1066',\n",
       " 'J82-3004',\n",
       " 'N03-1022',\n",
       " 'P08-1012',\n",
       " 'J98-3005',\n",
       " 'W04-3207',\n",
       " 'E03-1076',\n",
       " 'W04-2401',\n",
       " 'P00-1010',\n",
       " 'C02-2025',\n",
       " 'P98-2177',\n",
       " 'A97-1039',\n",
       " 'D07-1074',\n",
       " 'D07-1111',\n",
       " 'N03-1026',\n",
       " 'P09-1057',\n",
       " 'J08-4003',\n",
       " 'P07-1007',\n",
       " 'D07-1076',\n",
       " 'P00-1027',\n",
       " 'P06-1009',\n",
       " 'P85-1011',\n",
       " 'C94-1032',\n",
       " 'D07-1103',\n",
       " 'D11-1141',\n",
       " 'D11-1142',\n",
       " 'P11-1019',\n",
       " 'I05-3025',\n",
       " 'P05-1067',\n",
       " 'P85-1008',\n",
       " 'P05-1059',\n",
       " 'A00-1043',\n",
       " 'D08-1027',\n",
       " 'D12-1050',\n",
       " 'J94-2001',\n",
       " 'P06-1014',\n",
       " 'C96-1021',\n",
       " 'J98-2001',\n",
       " 'W04-3247',\n",
       " 'W03-1719',\n",
       " 'C92-3126',\n",
       " 'W02-1006',\n",
       " 'J95-4004',\n",
       " 'A94-1006',\n",
       " 'W04-1221',\n",
       " 'C08-1107',\n",
       " 'J93-2003',\n",
       " 'W01-0511',\n",
       " 'P03-1022',\n",
       " 'P96-1008',\n",
       " 'D09-1058',\n",
       " 'P04-1005',\n",
       " 'P95-1034',\n",
       " 'J01-3001',\n",
       " 'P83-1021',\n",
       " 'P98-1069',\n",
       " 'J06-3003',\n",
       " 'D08-1014',\n",
       " 'W01-1605',\n",
       " 'H01-1035',\n",
       " 'J99-4004',\n",
       " 'J94-4001',\n",
       " 'H05-1059',\n",
       " 'A97-1030',\n",
       " 'J94-3001',\n",
       " 'J04-4002',\n",
       " 'E06-1038',\n",
       " 'P06-4020',\n",
       " 'P11-1055',\n",
       " 'P08-1088',\n",
       " 'E99-1001',\n",
       " 'P07-2045',\n",
       " 'P86-1004',\n",
       " 'H05-1079',\n",
       " 'C10-1152',\n",
       " 'J99-3001',\n",
       " 'J99-4005',\n",
       " 'P97-1041',\n",
       " 'N06-2033',\n",
       " 'P98-2173',\n",
       " 'P84-1008',\n",
       " 'P09-1116',\n",
       " 'P93-1023',\n",
       " 'P02-1053',\n",
       " 'W04-3230',\n",
       " 'W02-0603',\n",
       " 'P03-1021',\n",
       " 'N07-1011',\n",
       " 'J05-3002',\n",
       " 'D10-1119',\n",
       " 'E06-1011',\n",
       " 'J08-2005',\n",
       " 'D07-1061',\n",
       " 'P09-1040',\n",
       " 'C08-1109',\n",
       " 'N09-1003',\n",
       " 'W00-0730',\n",
       " 'P05-1071',\n",
       " 'H94-1020',\n",
       " 'C90-3045',\n",
       " 'P06-1115',\n",
       " 'P09-2012',\n",
       " 'P03-1044',\n",
       " 'J05-4003',\n",
       " 'C02-1054',\n",
       " 'C04-1100',\n",
       " 'C02-1145',\n",
       " 'C04-1024',\n",
       " 'P93-1035',\n",
       " 'P06-1085',\n",
       " 'P06-2006',\n",
       " 'N07-4013',\n",
       " 'P07-1091',\n",
       " 'P98-2127',\n",
       " 'P96-1011',\n",
       " 'P06-1004',\n",
       " 'N10-1119',\n",
       " 'P11-1038',\n",
       " 'P03-1001',\n",
       " 'E06-1027',\n",
       " 'D08-1024',\n",
       " 'J03-1002',\n",
       " 'C92-1038',\n",
       " 'N09-1012',\n",
       " 'N03-2021',\n",
       " 'J88-1003',\n",
       " 'W03-1014',\n",
       " 'C96-1079',\n",
       " 'P08-1023',\n",
       " 'J95-2003',\n",
       " 'P92-1017',\n",
       " 'W02-1021',\n",
       " 'E89-1037',\n",
       " 'P98-1106',\n",
       " 'J93-1006',\n",
       " 'N07-1029',\n",
       " 'P93-1016',\n",
       " 'P06-1077',\n",
       " 'W02-1502',\n",
       " 'W02-0301',\n",
       " 'P09-1058',\n",
       " 'P10-4002',\n",
       " 'H05-2018',\n",
       " 'P01-1067',\n",
       " 'P04-1043',\n",
       " 'W04-0308',\n",
       " 'N04-4026',\n",
       " 'N13-1090',\n",
       " 'P99-1048',\n",
       " 'N03-1033',\n",
       " 'P09-1074',\n",
       " 'P04-1053',\n",
       " 'W02-1011',\n",
       " 'D11-1033',\n",
       " 'P98-2180',\n",
       " 'P06-2094',\n",
       " 'J07-2003',\n",
       " 'J91-4003',\n",
       " 'W04-3212',\n",
       " 'D08-1076',\n",
       " 'J88-2003',\n",
       " 'P99-1065',\n",
       " 'P05-1077',\n",
       " 'P02-1047',\n",
       " 'A97-1011',\n",
       " 'D09-1030',\n",
       " 'W01-0514',\n",
       " 'D07-1096',\n",
       " 'P06-3002',\n",
       " 'W03-0404',\n",
       " 'P04-1066',\n",
       " 'C90-3052',\n",
       " 'D10-1125',\n",
       " 'P02-1042',\n",
       " 'P06-2101',\n",
       " 'N03-1028',\n",
       " 'C00-2163',\n",
       " 'J96-2004',\n",
       " 'P07-1036',\n",
       " 'P04-1077',\n",
       " 'C92-1025',\n",
       " 'P08-1067',\n",
       " 'P11-2033',\n",
       " 'J98-1006',\n",
       " 'P09-1094',\n",
       " 'P84-1085',\n",
       " 'N04-1043',\n",
       " 'P05-1052',\n",
       " 'P91-1022',\n",
       " 'P89-1002',\n",
       " 'C88-2147',\n",
       " 'P05-1020',\n",
       " 'P05-1047',\n",
       " 'W03-0430',\n",
       " 'P97-1003',\n",
       " 'P94-1013',\n",
       " 'J02-1003',\n",
       " 'P03-1069',\n",
       " 'P06-1010',\n",
       " 'J93-3003',\n",
       " 'P00-1041',\n",
       " 'C08-1018',\n",
       " 'P09-1113',\n",
       " 'P05-1065',\n",
       " 'P07-1106',\n",
       " 'P95-1026',\n",
       " 'C04-1072',\n",
       " 'J87-1005',\n",
       " 'C92-2066',\n",
       " 'C88-2128',\n",
       " 'J93-2004',\n",
       " 'P90-1032',\n",
       " 'N04-1035',\n",
       " 'N01-1026',\n",
       " 'D10-1115',\n",
       " 'D07-1077',\n",
       " 'P11-1098',\n",
       " 'P08-1085',\n",
       " 'P07-1055',\n",
       " 'N04-1042',\n",
       " 'J08-4004',\n",
       " 'C04-1059',\n",
       " 'N06-1056',\n",
       " 'P98-1029',\n",
       " 'C04-1046',\n",
       " 'W00-1201',\n",
       " 'P06-1032',\n",
       " 'J93-1004',\n",
       " 'W00-0712',\n",
       " 'P05-1044',\n",
       " 'D10-1124',\n",
       " 'P91-1030',\n",
       " 'P08-1064',\n",
       " 'P06-1038',\n",
       " 'J90-2002',\n",
       " 'P06-1084',\n",
       " 'W03-1006',\n",
       " 'P86-1031',\n",
       " 'C04-1180',\n",
       " 'P10-1044',\n",
       " 'W03-1809',\n",
       " 'C88-1016',\n",
       " 'C04-1200',\n",
       " 'E06-1005',\n",
       " 'E06-1025',\n",
       " 'J04-1005',\n",
       " 'P06-1101',\n",
       " 'P04-3022',\n",
       " 'C00-1007',\n",
       " 'P04-1083',\n",
       " 'P99-1016',\n",
       " 'D11-1062',\n",
       " 'P06-1123',\n",
       " 'D09-1086',\n",
       " 'H05-1021',\n",
       " 'P10-1040',\n",
       " 'N07-1071',\n",
       " 'N04-1025',\n",
       " 'C96-1005',\n",
       " 'P02-1051',\n",
       " 'A00-2024',\n",
       " 'H05-1053',\n",
       " 'P06-1121',\n",
       " 'P10-1052',\n",
       " 'P90-1010',\n",
       " 'P97-1017',\n",
       " 'P06-1109',\n",
       " 'D08-1021',\n",
       " 'N09-1041',\n",
       " 'J93-1005',\n",
       " 'P06-2066',\n",
       " 'P97-1013',\n",
       " 'J94-4004',\n",
       " 'P96-1041',\n",
       " 'A92-1006',\n",
       " 'W04-3111',\n",
       " 'D09-1127',\n",
       " 'W00-1303',\n",
       " 'N04-1041',\n",
       " 'N01-1016',\n",
       " 'J93-2002',\n",
       " 'N10-1019',\n",
       " 'C10-1011',\n",
       " 'P04-1056',\n",
       " 'C96-2141',\n",
       " 'J04-1002',\n",
       " 'P07-1030',\n",
       " 'J00-1004',\n",
       " 'J08-1001',\n",
       " 'P07-1003',\n",
       " 'D08-1036',\n",
       " 'P03-1058',\n",
       " 'N03-1030',\n",
       " 'P99-1004',\n",
       " 'P10-1142',\n",
       " 'C96-1058',\n",
       " 'W02-2016',\n",
       " 'P93-1003',\n",
       " 'W03-0424',\n",
       " 'J97-4005',\n",
       " 'E09-1013',\n",
       " 'C02-1150',\n",
       " 'P07-1092',\n",
       " 'E03-1071',\n",
       " 'C08-1114',\n",
       " 'C10-2005',\n",
       " 'P93-1002',\n",
       " 'W03-1008',\n",
       " 'N04-1023',\n",
       " 'P08-2026',\n",
       " 'P06-1134',\n",
       " 'J98-4003',\n",
       " 'P09-1011',\n",
       " 'P08-1068',\n",
       " 'P07-1098',\n",
       " 'C04-1081',\n",
       " 'N01-1006',\n",
       " 'P03-2041',\n",
       " 'W00-1401',\n",
       " 'W03-1011',\n",
       " 'P06-1104',\n",
       " 'N13-1039',\n",
       " 'N12-1067',\n",
       " 'P12-1092',\n",
       " 'C94-1079',\n",
       " 'N07-1038',\n",
       " 'N10-1020',\n",
       " 'J03-3001',\n",
       " 'J98-2002',\n",
       " 'P06-1095',\n",
       " 'D07-1114',\n",
       " 'D08-1068',\n",
       " 'W01-1313',\n",
       " 'N04-1022',\n",
       " 'D08-1089',\n",
       " 'P03-1029',\n",
       " 'P04-1015',\n",
       " 'P83-1007',\n",
       " 'P94-1019',\n",
       " 'P88-1012',\n",
       " 'P09-1019',\n",
       " 'W04-0803',\n",
       " 'P10-1110',\n",
       " 'P10-1146',\n",
       " 'P99-1008',\n",
       " 'N04-1030',\n",
       " 'A97-1004',\n",
       " 'P05-1017',\n",
       " 'P08-1119',\n",
       " 'J03-4003',\n",
       " 'D09-1005',\n",
       " 'P08-1109',\n",
       " 'N03-1020',\n",
       " 'E03-1009',\n",
       " 'P06-1015',\n",
       " 'N10-1115',\n",
       " 'J88-2006',\n",
       " 'P91-1017',\n",
       " 'C02-1144',\n",
       " 'N06-1041',\n",
       " 'N01-1025',\n",
       " 'P06-1011',\n",
       " 'A88-1019',\n",
       " 'W04-2406',\n",
       " 'N10-1063',\n",
       " 'L08-1093',\n",
       " 'D07-1091',\n",
       " 'D07-1003',\n",
       " 'P93-1022',\n",
       " 'D07-1097',\n",
       " 'P02-1018',\n",
       " 'P97-1023',\n",
       " 'W01-0513',\n",
       " 'N06-1003',\n",
       " 'D10-1120',\n",
       " 'D07-1080',\n",
       " 'P05-1015',\n",
       " 'N07-1051',\n",
       " 'P03-1051',\n",
       " 'P92-1032',\n",
       " 'W02-1028',\n",
       " 'P93-1032',\n",
       " 'H92-1045',\n",
       " 'E09-1005',\n",
       " 'D09-1026',\n",
       " 'P08-1090',\n",
       " 'E06-1043',\n",
       " 'P03-1010',\n",
       " 'H93-1052',\n",
       " 'J95-2002',\n",
       " 'W04-3205',\n",
       " 'D09-1120',\n",
       " 'E89-1009',\n",
       " 'P05-1012',\n",
       " 'N04-1001',\n",
       " 'D08-1020',\n",
       " 'A00-2004',\n",
       " 'P09-1026',\n",
       " 'P01-1017',\n",
       " 'P07-1125',\n",
       " 'P02-1031',\n",
       " 'W02-2026',\n",
       " 'N04-1033',\n",
       " 'P06-1072',\n",
       " 'D09-1098',\n",
       " 'J97-1005',\n",
       " 'P07-1123',\n",
       " 'C88-2121',\n",
       " 'J04-3002',\n",
       " 'H91-1060',\n",
       " 'P04-1035',\n",
       " 'N04-1019',\n",
       " 'P07-1096',\n",
       " 'D07-1031',\n",
       " 'H05-1011',\n",
       " 'D11-1129',\n",
       " 'P99-1042',\n",
       " 'C04-1073',\n",
       " 'C04-1146',\n",
       " 'P05-1073',\n",
       " 'P02-1050',\n",
       " 'P03-1002',\n",
       " 'W02-0109',\n",
       " 'N10-1013',\n",
       " 'P04-1014',\n",
       " 'C00-1072',\n",
       " 'P96-1042',\n",
       " 'P10-2041',\n",
       " 'P83-1019',\n",
       " 'P11-2008',\n",
       " 'J08-2002',\n",
       " 'A92-1018',\n",
       " 'C92-1019',\n",
       " 'H05-1045',\n",
       " 'P03-1004',\n",
       " 'N07-1047',\n",
       " 'J97-1003',\n",
       " 'J07-4004',\n",
       " 'P99-1014',\n",
       " 'P95-1050',\n",
       " 'A92-1021',\n",
       " 'W02-1210',\n",
       " 'W04-2407',\n",
       " 'A97-1029',\n",
       " 'C04-1041',\n",
       " 'J02-4002',\n",
       " 'J92-1001',\n",
       " 'P02-1022',\n",
       " 'P08-1114',\n",
       " 'P04-1054',\n",
       " 'E06-1002',\n",
       " 'D07-1071',\n",
       " 'J00-2004',\n",
       " 'W02-0817',\n",
       " 'P89-1031',\n",
       " 'J97-2003',\n",
       " 'D08-1011',\n",
       " 'P00-1056']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(\"./From-ScisummNet-2019\")\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac0e9f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_end = int(len(files)*0.7)\n",
    "# val_end = int(len(files)*0.1)+train_end\n",
    "train_docs = files[0:train_end]\n",
    "# val_docs = files[train_end:val_end]\n",
    "test_docs = files[train_end:len(files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e713843c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f P83-1020\n",
      "f W02-1039\n",
      "f P96-1021\n",
      "f N06-1020\n",
      "f C86-1016\n",
      "f C92-2070\n",
      "f D08-1082\n",
      "f J01-2002\n",
      "f C02-1114\n",
      "f P85-1018\n",
      "f P07-1032\n",
      "f W00-1427\n",
      "f C04-1111\n",
      "f J97-1002\n",
      "f W04-3237\n",
      "f E87-1002\n",
      "eror in  E87-1002\n",
      "f P93-1041\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P93-1041/annotation/P93-1041.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P90-1034\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P90-1034/annotation/P90-1034.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P98-1035\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P98-1035/annotation/P98-1035.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f W02-0505\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/W02-0505/annotation/W02-0505.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P13-1045\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P13-1045/annotation/P13-1045.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f A00-2026\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/A00-2026/annotation/A00-2026.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f J03-4004\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/J03-4004/annotation/J03-4004.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f N03-1003\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/N03-1003/annotation/N03-1003.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f C90-2067\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/C90-2067/annotation/C90-2067.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P84-1075\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P84-1075/annotation/P84-1075.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f W02-0908\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/W02-0908/annotation/W02-0908.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f M95-1005\n",
      "f P07-1028\n",
      "f C00-2136\n",
      "f P01-1019\n",
      "f N10-1056\n",
      "f J81-4003\n",
      "f P93-1024\n",
      "f C90-3030\n",
      "f W02-2024\n",
      "f P98-1013\n",
      "f P03-1019\n",
      "f P07-1065\n",
      "f I05-3017\n",
      "f P07-1056\n",
      "f W03-0419\n",
      "f W00-0726\n",
      "f A00-2031\n",
      "f D07-1090\n",
      "f P02-1040\n",
      "f P05-1011\n",
      "f P02-1043\n",
      "f A00-2009\n",
      "f H94-1046\n",
      "f C00-1044\n",
      "f P11-1138\n",
      "f C02-1011\n",
      "f C96-1055\n",
      "f N06-2015\n",
      "f N03-1024\n",
      "f P08-1101\n",
      "f P96-1025\n",
      "f P02-1019\n",
      "f P09-1088\n",
      "f C94-1042\n",
      "f P99-1068\n",
      "f N07-1018\n",
      "f D07-1043\n",
      "f J93-1007\n",
      "f C08-1022\n",
      "f P01-1030\n",
      "f J01-2001\n",
      "f N01-1008\n",
      "f P05-3026\n",
      "f P96-1024\n",
      "f A00-2019\n",
      "f E06-1042\n",
      "f N06-1014\n",
      "f P03-1011\n",
      "f P11-1016\n",
      "f C92-2082\n",
      "f P02-1038\n",
      "f J01-4004\n",
      "f N09-1046\n",
      "f D11-1125\n",
      "f P94-1020\n",
      "f W04-2609\n",
      "f P09-1027\n",
      "f H05-1073\n",
      "f E06-1051\n",
      "f P00-1065\n",
      "f P04-1085\n",
      "f P02-1017\n",
      "f J91-1002\n",
      "f J00-3004\n",
      "f D09-1159\n",
      "f P08-1004\n",
      "f P02-1014\n",
      "f W04-3250\n",
      "f W02-1018\n",
      "f J00-4003\n",
      "f J03-3002\n",
      "f P00-1071\n",
      "f D07-1101\n",
      "f P84-1018\n",
      "f N09-1009\n",
      "f P02-1060\n",
      "f A97-1052\n",
      "f C00-2137\n",
      "f P05-1057\n",
      "f D08-1022\n",
      "f C92-3150\n",
      "f J92-1004\n",
      "f P06-1067\n",
      "f E06-1031\n",
      "f J04-4004\n",
      "f N06-1039\n",
      "f W02-2018\n",
      "f P07-1121\n",
      "f W04-0807\n",
      "f P87-1033\n",
      "f N03-2002\n",
      "f W02-1001\n",
      "f J05-1003\n",
      "f D08-1031\n",
      "f J93-2005\n",
      "f N01-1023\n",
      "f W03-0407\n",
      "f C04-1051\n",
      "f N04-1015\n",
      "eror in  N04-1015\n",
      "f D10-1001\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/D10-1001/annotation/D10-1001.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f A00-1031\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/A00-1031/annotation/A00-1031.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P08-2007\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P08-2007/annotation/P08-2007.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P09-1010\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P09-1010/annotation/P09-1010.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f I08-1059\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/I08-1059/annotation/I08-1059.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f J00-4005\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/J00-4005/annotation/J00-4005.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f E99-1023\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/E99-1023/annotation/E99-1023.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f M95-1012\n",
      "f C94-2178\n",
      "f P08-1086\n",
      "f W04-3208\n",
      "f W03-1508\n",
      "f N06-1058\n",
      "f P01-1064\n",
      "f P88-1020\n",
      "f J02-2003\n",
      "f E06-1040\n",
      "f P07-1031\n",
      "f J07-3004\n",
      "f P02-1006\n",
      "f P02-1062\n",
      "f C94-2174\n",
      "f N06-1006\n",
      "f N09-1028\n",
      "f P90-1005\n",
      "f C04-1010\n",
      "f P03-1071\n",
      "f N04-1021\n",
      "f A94-1009\n",
      "f N01-1020\n",
      "f P08-1024\n",
      "f P09-1068\n",
      "f N07-1030\n",
      "f J86-3001\n",
      "f J03-1005\n",
      "f N04-3012\n",
      "f D12-1133\n",
      "f N12-1052\n",
      "f H05-1066\n",
      "f P07-1094\n",
      "f P08-1108\n",
      "f P04-1075\n",
      "f P93-1001\n",
      "f N04-1014\n",
      "f P11-1020\n",
      "f W04-3219\n",
      "f J93-1003\n",
      "f S10-1011\n",
      "f P96-1006\n",
      "f J93-2006\n",
      "f P95-1007\n",
      "f J94-2003\n",
      "f D07-1002\n",
      "f P09-1042\n",
      "f E99-1010\n",
      "f W03-1730\n",
      "f D09-1001\n",
      "f J94-4003\n",
      "f N03-1021\n",
      "f A94-1016\n",
      "f P93-1020\n",
      "f J02-1002\n",
      "f H94-1048\n",
      "f W03-0301\n",
      "f W04-0811\n",
      "f J94-4002\n",
      "f P97-1009\n",
      "f N04-4038\n",
      "f P04-1061\n",
      "f J03-3005\n",
      "f J91-1003\n",
      "f J90-1003\n",
      "f P99-1059\n",
      "f P00-1037\n",
      "f W04-3103\n",
      "f D10-1048\n",
      "f P08-1084\n",
      "f J96-1002\n",
      "f W01-0501\n",
      "f H05-1010\n",
      "f W03-0405\n",
      "f H92-1026\n",
      "f P04-1018\n",
      "f J97-3002\n",
      "f P01-1008\n",
      "f J96-1001\n",
      "f N03-1017\n",
      "f C04-1080\n",
      "f P07-1004\n",
      "f P05-1036\n",
      "f P91-1027\n",
      "f P03-1056\n",
      "f P93-1008\n",
      "f W03-1028\n",
      "f P04-1041\n",
      "f P97-1005\n",
      "f P06-1124\n",
      "f J98-2004\n",
      "f J92-4007\n",
      "f P92-1005\n",
      "f C96-2183\n",
      "f P94-1012\n",
      "f W00-1308\n",
      "f J98-4004\n",
      "f W03-1812\n",
      "f P09-1077\n",
      "f P91-1034\n",
      "f J87-1004\n",
      "f N04-1013\n",
      "f P02-1039\n",
      "f W02-0902\n",
      "f N09-1036\n",
      "f W03-0501\n",
      "f D08-1092\n",
      "f P98-1012\n",
      "f P07-1005\n",
      "f H05-1004\n",
      "eror in  H05-1004\n",
      "f J92-4003\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/J92-4003/annotation/J92-4003.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f D08-1035\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/D08-1035/annotation/D08-1035.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f D07-1072\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/D07-1072/annotation/D07-1072.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f D07-1104\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/D07-1104/annotation/D07-1104.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P91-1023\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P91-1023/annotation/P91-1023.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f N04-4015\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/N04-4015/annotation/N04-4015.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P02-1033\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P02-1033/annotation/P02-1033.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P98-2182\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P98-2182/annotation/P98-2182.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P89-1010\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P89-1010/annotation/P89-1010.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P03-1023\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P03-1023/annotation/P03-1023.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P03-1054\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P03-1054/annotation/P03-1054.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f J03-1003\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/J03-1003/annotation/J03-1003.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f W04-2705\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/W04-2705/annotation/W04-2705.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f N03-1016\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/N03-1016/annotation/N03-1016.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P02-1035\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P02-1035/annotation/P02-1035.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P07-1049\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P07-1049/annotation/P07-1049.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P03-1012\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P03-1012/annotation/P03-1012.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f N06-1025\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/N06-1025/annotation/N06-1025.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f I05-2038\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/I05-2038/annotation/I05-2038.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f J04-2003\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/J04-2003/annotation/J04-2003.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P08-1066\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P08-1066/annotation/P08-1066.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P05-1034\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P05-1034/annotation/P05-1034.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f W04-3206\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/W04-3206/annotation/W04-3206.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P97-1035\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P97-1035/annotation/P97-1035.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P06-1043\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P06-1043/annotation/P06-1043.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P07-1037\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P07-1037/annotation/P07-1037.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f N06-1011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/N06-1011/annotation/N06-1011.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f S10-1010\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/S10-1010/annotation/S10-1010.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f N12-1047\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/N12-1047/annotation/N12-1047.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P07-1019\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P07-1019/annotation/P07-1019.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P06-2005\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P06-2005/annotation/P06-2005.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P03-1035\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P03-1035/annotation/P03-1035.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f N09-2004\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/N09-2004/annotation/N09-2004.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f J06-1003\n",
      "f W03-1728\n",
      "f P97-1063\n",
      "f P06-1114\n",
      "f P07-1059\n",
      "f P07-1034\n",
      "f H93-1051\n",
      "f N01-1021\n",
      "f N03-1014\n",
      "f P99-1041\n",
      "f W03-1017\n",
      "f P08-2012\n",
      "f P95-1037\n",
      "f C10-2028\n",
      "f P03-1003\n",
      "f J99-2004\n",
      "f P05-1001\n",
      "f N09-1037\n",
      "f P87-1022\n",
      "f P99-1032\n",
      "f P89-1009\n",
      "f D08-1016\n",
      "f H91-1026\n",
      "f P92-1008\n",
      "f C04-1197\n",
      "f H05-1012\n",
      "f W00-0403\n",
      "f D07-1109\n",
      "f P05-1074\n",
      "f J93-1001\n",
      "f N07-1023\n",
      "f D07-1007\n",
      "f P01-1005\n",
      "f P96-1038\n",
      "f P04-1021\n",
      "f P95-1021\n",
      "f P93-1005\n",
      "f W00-0717\n",
      "f C94-1027\n",
      "f J93-1002\n",
      "f H05-1043\n",
      "f P98-1034\n",
      "f N04-1016\n",
      "f N06-1033\n",
      "f P04-1013\n",
      "f P01-1025\n",
      "f C90-3063\n",
      "f N01-1024\n",
      "f W04-2319\n",
      "f P03-2026\n",
      "f P07-1073\n",
      "f E06-1032\n",
      "f P03-1013\n",
      "f E06-1015\n",
      "f W03-0428\n",
      "f J99-1003\n",
      "f P05-1072\n",
      "f C86-1045\n",
      "f P06-2014\n",
      "f J01-3003\n",
      "f W04-1013\n",
      "f J05-1004\n",
      "f W03-1810\n",
      "f P09-2004\n",
      "f P96-1027\n",
      "f P00-1016\n",
      "f W04-3239\n",
      "f H05-1091\n",
      "f I05-3027\n",
      "f C94-2195\n",
      "f S12-1053\n",
      "f P11-2031\n",
      "f P08-1030\n",
      "f J02-3001\n",
      "f C90-3044\n",
      "f P06-1005\n",
      "f P06-1055\n",
      "f D11-1014\n",
      "f P05-1010\n",
      "f E03-1008\n",
      "f W04-3236\n",
      "f P10-1001\n",
      "f P03-1009\n",
      "f P99-1069\n",
      "f P02-1034\n",
      "f P05-1018\n",
      "f J80-3003\n",
      "f P05-1033\n",
      "f P06-1097\n",
      "f W04-3213\n",
      "f P99-1071\n",
      "f P08-1036\n",
      "f P05-1045\n",
      "f P99-1067\n",
      "f N10-1061\n",
      "f P07-1107\n",
      "f D08-1065\n",
      "f P98-1010\n",
      "f P06-1103\n",
      "f P05-2008\n",
      "f P05-1066\n",
      "f P02-1046\n",
      "f J10-3003\n",
      "f W03-0425\n",
      "f W02-1503\n",
      "f W04-3201\n",
      "f P98-2204\n",
      "f D08-1083\n",
      "f W01-0521\n",
      "f P06-1091\n",
      "f P88-1015\n",
      "f D09-1101\n",
      "f J98-1001\n",
      "f J90-1004\n",
      "f J10-4006\n",
      "f P02-1001\n",
      "f P00-1058\n",
      "f H93-1061\n",
      "f H05-1044\n",
      "f P05-1022\n",
      "f P08-1076\n",
      "f P94-1002\n",
      "f D11-1006\n",
      "f A00-2034\n",
      "f J08-1002\n",
      "f P08-1115\n",
      "f P09-1104\n",
      "f C02-1139\n",
      "f P98-1112\n",
      "f N06-2013\n",
      "f D08-1059\n",
      "f J97-3003\n",
      "f P09-1039\n",
      "f J09-3003\n",
      "f P06-1066\n",
      "f J82-3004\n",
      "f N03-1022\n",
      "f P08-1012\n",
      "f J98-3005\n",
      "f W04-3207\n",
      "f E03-1076\n",
      "f W04-2401\n",
      "f P00-1010\n",
      "f C02-2025\n",
      "f P98-2177\n",
      "f A97-1039\n",
      "f D07-1074\n",
      "f D07-1111\n",
      "f N03-1026\n",
      "f P09-1057\n",
      "f J08-4003\n",
      "f P07-1007\n",
      "f D07-1076\n",
      "f P00-1027\n",
      "f P06-1009\n",
      "f P85-1011\n",
      "f C94-1032\n",
      "f D07-1103\n",
      "f D11-1141\n",
      "f D11-1142\n",
      "f P11-1019\n",
      "f I05-3025\n",
      "f P05-1067\n",
      "f P85-1008\n",
      "f P05-1059\n",
      "f A00-1043\n",
      "f D08-1027\n",
      "f D12-1050\n",
      "f J94-2001\n",
      "f P06-1014\n",
      "f C96-1021\n",
      "f J98-2001\n",
      "f W04-3247\n",
      "f W03-1719\n",
      "f C92-3126\n",
      "f W02-1006\n",
      "f J95-4004\n",
      "f A94-1006\n",
      "f W04-1221\n",
      "f C08-1107\n",
      "f J93-2003\n",
      "f W01-0511\n",
      "f P03-1022\n",
      "f P96-1008\n",
      "f D09-1058\n",
      "f P04-1005\n",
      "f P95-1034\n",
      "f J01-3001\n",
      "f P83-1021\n",
      "f P98-1069\n",
      "f J06-3003\n",
      "f D08-1014\n",
      "f W01-1605\n",
      "f H01-1035\n",
      "f J99-4004\n",
      "f J94-4001\n",
      "f H05-1059\n",
      "f A97-1030\n",
      "f J94-3001\n",
      "f J04-4002\n",
      "f E06-1038\n",
      "f P06-4020\n",
      "f P11-1055\n",
      "f P08-1088\n",
      "f E99-1001\n",
      "f P07-2045\n",
      "f P86-1004\n",
      "f H05-1079\n",
      "f C10-1152\n",
      "f J99-3001\n",
      "f J99-4005\n",
      "f P97-1041\n",
      "f N06-2033\n",
      "f P98-2173\n",
      "f P84-1008\n",
      "f P09-1116\n",
      "f P93-1023\n",
      "f P02-1053\n",
      "f W04-3230\n",
      "f W02-0603\n",
      "f P03-1021\n",
      "f N07-1011\n",
      "f J05-3002\n",
      "f D10-1119\n",
      "f E06-1011\n",
      "f J08-2005\n",
      "f D07-1061\n",
      "f P09-1040\n",
      "f C08-1109\n",
      "f N09-1003\n",
      "f W00-0730\n",
      "f P05-1071\n",
      "f H94-1020\n",
      "f C90-3045\n",
      "f P06-1115\n",
      "f P09-2012\n",
      "f P03-1044\n",
      "f J05-4003\n",
      "f C02-1054\n",
      "f C04-1100\n",
      "f C02-1145\n",
      "eror in  C02-1145\n",
      "f C04-1024\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/C04-1024/annotation/C04-1024.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P93-1035\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P93-1035/annotation/P93-1035.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P06-1085\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P06-1085/annotation/P06-1085.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P06-2006\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P06-2006/annotation/P06-2006.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f N07-4013\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/N07-4013/annotation/N07-4013.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P07-1091\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P07-1091/annotation/P07-1091.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P98-2127\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P98-2127/annotation/P98-2127.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P96-1011\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P96-1011/annotation/P96-1011.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P06-1004\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P06-1004/annotation/P06-1004.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f N10-1119\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/N10-1119/annotation/N10-1119.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P11-1038\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P11-1038/annotation/P11-1038.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P03-1001\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P03-1001/annotation/P03-1001.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f E06-1027\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/E06-1027/annotation/E06-1027.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f D08-1024\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/D08-1024/annotation/D08-1024.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f J03-1002\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/J03-1002/annotation/J03-1002.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f C92-1038\n",
      "f N09-1012\n",
      "f N03-2021\n",
      "f J88-1003\n",
      "f W03-1014\n",
      "f C96-1079\n",
      "f P08-1023\n",
      "f J95-2003\n",
      "f P92-1017\n",
      "f W02-1021\n",
      "f E89-1037\n",
      "f P98-1106\n",
      "f J93-1006\n",
      "f N07-1029\n",
      "f P93-1016\n",
      "f P06-1077\n",
      "f W02-1502\n",
      "f W02-0301\n",
      "f P09-1058\n",
      "f P10-4002\n",
      "f H05-2018\n",
      "f P01-1067\n",
      "f P04-1043\n",
      "f W04-0308\n",
      "f N04-4026\n",
      "f N13-1090\n",
      "f P99-1048\n",
      "f N03-1033\n",
      "f P09-1074\n",
      "f P04-1053\n",
      "f W02-1011\n",
      "f D11-1033\n",
      "f P98-2180\n",
      "f P06-2094\n",
      "f J07-2003\n",
      "f J91-4003\n",
      "f W04-3212\n",
      "f D08-1076\n",
      "f J88-2003\n",
      "f P99-1065\n",
      "f P05-1077\n",
      "f P02-1047\n",
      "f A97-1011\n",
      "f D09-1030\n",
      "f W01-0514\n",
      "f D07-1096\n",
      "f P06-3002\n",
      "f W03-0404\n",
      "f P04-1066\n",
      "f C90-3052\n",
      "f D10-1125\n",
      "f P02-1042\n",
      "f P06-2101\n",
      "f N03-1028\n",
      "f C00-2163\n",
      "f J96-2004\n",
      "f P07-1036\n",
      "f P04-1077\n",
      "f C92-1025\n",
      "f P08-1067\n",
      "f P11-2033\n",
      "f J98-1006\n",
      "f P09-1094\n",
      "f P84-1085\n",
      "eror in  P84-1085\n",
      "f N04-1043\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/N04-1043/annotation/N04-1043.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P05-1052\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P05-1052/annotation/P05-1052.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P91-1022\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P91-1022/annotation/P91-1022.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P89-1002\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P89-1002/annotation/P89-1002.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f C88-2147\n",
      "f P05-1020\n",
      "f P05-1047\n",
      "f W03-0430\n",
      "f P97-1003\n",
      "f P94-1013\n",
      "f J02-1003\n",
      "f P03-1069\n",
      "f P06-1010\n",
      "f J93-3003\n",
      "f P00-1041\n",
      "f C08-1018\n",
      "f P09-1113\n",
      "f P05-1065\n",
      "f P07-1106\n",
      "f P95-1026\n",
      "f C04-1072\n",
      "f J87-1005\n",
      "f C92-2066\n",
      "eror in  C92-2066\n",
      "f C88-2128\n",
      "f J93-2004\n",
      "f P90-1032\n",
      "f N04-1035\n",
      "f N01-1026\n",
      "f D10-1115\n",
      "f D07-1077\n",
      "f P11-1098\n",
      "f P08-1085\n",
      "f P07-1055\n",
      "f N04-1042\n",
      "f J08-4004\n",
      "f C04-1059\n",
      "f N06-1056\n",
      "f P98-1029\n",
      "f C04-1046\n",
      "f W00-1201\n",
      "f P06-1032\n",
      "f J93-1004\n",
      "f W00-0712\n",
      "f P05-1044\n",
      "f D10-1124\n",
      "f P91-1030\n",
      "f P08-1064\n",
      "f P06-1038\n",
      "f J90-2002\n",
      "f P06-1084\n",
      "f W03-1006\n",
      "f P86-1031\n",
      "f C04-1180\n",
      "eror in  C04-1180\n",
      "f P10-1044\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P10-1044/annotation/P10-1044.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f W03-1809\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/W03-1809/annotation/W03-1809.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f C88-1016\n",
      "f C04-1200\n",
      "f E06-1005\n",
      "f E06-1025\n",
      "f J04-1005\n",
      "f P06-1101\n",
      "f P04-3022\n",
      "f C00-1007\n",
      "f P04-1083\n",
      "f P99-1016\n",
      "f D11-1062\n",
      "f P06-1123\n",
      "f D09-1086\n",
      "f H05-1021\n",
      "f P10-1040\n",
      "f N07-1071\n",
      "f N04-1025\n",
      "f C96-1005\n",
      "f P02-1051\n",
      "f A00-2024\n",
      "f H05-1053\n",
      "f P06-1121\n",
      "f P10-1052\n",
      "f P90-1010\n",
      "f P97-1017\n",
      "f P06-1109\n",
      "f D08-1021\n",
      "f N09-1041\n",
      "f J93-1005\n",
      "f P06-2066\n",
      "f P97-1013\n",
      "f J94-4004\n",
      "f P96-1041\n",
      "f A92-1006\n",
      "f W04-3111\n",
      "f D09-1127\n",
      "f W00-1303\n",
      "f N04-1041\n",
      "f N01-1016\n",
      "f J93-2002\n",
      "f N10-1019\n",
      "f C10-1011\n",
      "f P04-1056\n",
      "f C96-2141\n",
      "f J04-1002\n",
      "f P07-1030\n",
      "f J00-1004\n",
      "f J08-1001\n",
      "f P07-1003\n",
      "f D08-1036\n",
      "f P03-1058\n",
      "f N03-1030\n",
      "f P99-1004\n",
      "f P10-1142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f C96-1058\n",
      "f W02-2016\n",
      "f P93-1003\n",
      "f W03-0424\n",
      "f J97-4005\n",
      "f E09-1013\n",
      "f C02-1150\n",
      "f P07-1092\n",
      "f E03-1071\n",
      "f C08-1114\n",
      "f C10-2005\n",
      "f P93-1002\n",
      "f W03-1008\n",
      "f N04-1023\n",
      "f P08-2026\n",
      "f P06-1134\n",
      "f J98-4003\n",
      "f P09-1011\n",
      "f P08-1068\n",
      "f P07-1098\n",
      "f C04-1081\n",
      "f N01-1006\n",
      "f P03-2041\n",
      "f W00-1401\n",
      "f W03-1011\n",
      "f P06-1104\n",
      "f N13-1039\n",
      "f N12-1067\n",
      "f P12-1092\n",
      "f C94-1079\n",
      "f N07-1038\n",
      "f N10-1020\n",
      "f J03-3001\n",
      "f J98-2002\n",
      "f P06-1095\n",
      "f D07-1114\n",
      "f D08-1068\n",
      "f W01-1313\n",
      "f N04-1022\n",
      "f D08-1089\n",
      "f P03-1029\n",
      "f P04-1015\n",
      "f P83-1007\n",
      "f P94-1019\n",
      "f P88-1012\n",
      "f P09-1019\n",
      "f W04-0803\n",
      "f P10-1110\n",
      "f P10-1146\n",
      "f P99-1008\n",
      "f N04-1030\n",
      "f A97-1004\n",
      "f P05-1017\n",
      "f P08-1119\n",
      "f J03-4003\n",
      "f D09-1005\n",
      "f P08-1109\n",
      "f N03-1020\n",
      "f E03-1009\n",
      "f P06-1015\n",
      "f N10-1115\n",
      "f J88-2006\n",
      "f P91-1017\n",
      "f C02-1144\n",
      "f N06-1041\n",
      "f N01-1025\n",
      "f P06-1011\n",
      "f A88-1019\n",
      "f W04-2406\n",
      "f N10-1063\n",
      "f L08-1093\n",
      "eror in  L08-1093\n",
      "f D07-1091\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/D07-1091/annotation/D07-1091.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f D07-1003\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/D07-1003/annotation/D07-1003.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P93-1022\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P93-1022/annotation/P93-1022.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f D07-1097\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/D07-1097/annotation/D07-1097.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P02-1018\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P02-1018/annotation/P02-1018.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P97-1023\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P97-1023/annotation/P97-1023.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f W01-0513\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/W01-0513/annotation/W01-0513.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f N06-1003\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/N06-1003/annotation/N06-1003.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f D10-1120\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/D10-1120/annotation/D10-1120.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f D07-1080\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/D07-1080/annotation/D07-1080.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P05-1015\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P05-1015/annotation/P05-1015.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f N07-1051\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/N07-1051/annotation/N07-1051.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P03-1051\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P03-1051/annotation/P03-1051.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P92-1032\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P92-1032/annotation/P92-1032.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f W02-1028\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/W02-1028/annotation/W02-1028.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f P93-1032\n",
      "eror in  <_io.TextIOWrapper name='From-ScisummNet-2019/P93-1032/annotation/P93-1032.ann.txt' mode='r' encoding='UTF-8'>\n",
      "f H92-1045\n",
      "f E09-1005\n",
      "f D09-1026\n",
      "f P08-1090\n",
      "f E06-1043\n",
      "f P03-1010\n",
      "f H93-1052\n",
      "f J95-2002\n",
      "f W04-3205\n",
      "f D09-1120\n",
      "f E89-1009\n",
      "f P05-1012\n",
      "f N04-1001\n",
      "f D08-1020\n",
      "f A00-2004\n",
      "f P09-1026\n",
      "f P01-1017\n",
      "f P07-1125\n",
      "f P02-1031\n",
      "f W02-2026\n",
      "f N04-1033\n",
      "f P06-1072\n",
      "f D09-1098\n",
      "f J97-1005\n",
      "f P07-1123\n",
      "f C88-2121\n",
      "f J04-3002\n",
      "f H91-1060\n",
      "f P04-1035\n",
      "f N04-1019\n",
      "f P07-1096\n",
      "f D07-1031\n",
      "f H05-1011\n",
      "f D11-1129\n",
      "f P99-1042\n",
      "f C04-1073\n",
      "f C04-1146\n",
      "f P05-1073\n",
      "f P02-1050\n",
      "f P03-1002\n",
      "f W02-0109\n",
      "f N10-1013\n",
      "f P04-1014\n",
      "f C00-1072\n",
      "f P96-1042\n",
      "f P10-2041\n",
      "f P83-1019\n",
      "f P11-2008\n",
      "f J08-2002\n",
      "f A92-1018\n",
      "f C92-1019\n",
      "f H05-1045\n",
      "f P03-1004\n",
      "f N07-1047\n",
      "f J97-1003\n",
      "f J07-4004\n",
      "f P99-1014\n",
      "f P95-1050\n",
      "f A92-1021\n",
      "f W02-1210\n",
      "f W04-2407\n",
      "f A97-1029\n",
      "f C04-1041\n",
      "f J02-4002\n",
      "f J92-1001\n",
      "f P02-1022\n",
      "f P08-1114\n",
      "f P04-1054\n",
      "f E06-1002\n",
      "f D07-1071\n",
      "f J00-2004\n",
      "f W02-0817\n",
      "f P89-1031\n",
      "f J97-2003\n",
      "f D08-1011\n",
      "f P00-1056\n"
     ]
    }
   ],
   "source": [
    "def preprocess(example_sent):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    word_tokens = word_tokenize(example_sent.lower())\n",
    "\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_sentence = [w for w in filtered_sentence if w.isalpha()]\n",
    "#     print(filtered_sentence)\n",
    "    new = \" \" \n",
    "    a = new.join(filtered_sentence)\n",
    "    return a\n",
    "\n",
    "def get_dataset(files):\n",
    "    pairs_lis = []\n",
    "    new_corpus_prev = None\n",
    "    for z,f in enumerate(files):\n",
    "        print(\"f\",f)\n",
    "        try:\n",
    "            citants = pd.read_json(\"From-ScisummNet-2019/\"+str(f)+\"/citing_sentences.json\")\n",
    "            citants = citants[['citance_No','clean_text']]\n",
    "            queries = list(citants['clean_text'])\n",
    "            cite_no = list(citants.citance_No)\n",
    "            tree = ET.parse(\"From-ScisummNet-2019/\"+f+\"/Reference_XML/\"+f+\".xml\")\n",
    "            root = tree.getroot()\n",
    "            final1=[]\n",
    "            final2=[]\n",
    "            i = 0\n",
    "            total = len(root)\n",
    "            for a in root:\n",
    "                for b in a:\n",
    "                    final1.append(b.text)\n",
    "                    if i == 0:\n",
    "                        final2.append(\"Abstract\")\n",
    "                    if i == 1:\n",
    "                        final2.append(\"Introduction\")\n",
    "                    elif i < total-2:\n",
    "                        final2.append(\"Experiment/Discussion\")\n",
    "                    if i == total-2 or i == total-1:\n",
    "                        final2.append(\"Results/Conclusion\")\n",
    "                    if i == total:\n",
    "                        final2.append(\"Acknowledgment\")\n",
    "                i = i+1\n",
    "\n",
    "            d={'col1':final1,'col2':final2}\n",
    "            rp = pd.DataFrame(data=d)\n",
    "            ann = \"From-ScisummNet-2019/\"+f+\"/annotation/\"+f+\".ann.txt\"\n",
    "            with open(ann,\"r\") as f:\n",
    "                data = f.read()\n",
    "            idx = {'Citance Number':0,'Reference Article':1,'Citing Article':2,'Citation Marker Offset':3,'Citation Marker':4,'Citation Offset':5,'Reference Offset':7}\n",
    "            gt = {}\n",
    "            lines = data.split('\\n')\n",
    "            for line in lines:\n",
    "                lis = line.split('|')\n",
    "                if len(lis)==11:\n",
    "                    cit_no = lis[0].split(':')[1]\n",
    "                    ref_off = lis[7].split(':')[1].strip()\n",
    "    #                 ref_off = ref_off.strip(\"][\").split(\", \")\n",
    "    #                 exec(\"ref_off2=\"+ref_off)\n",
    "                    import ast\n",
    "                    ref_off = ast.literal_eval(ref_off)\n",
    "                    ref_off = list(map(int, ref_off))\n",
    "                    gt[int(cit_no)] = ref_off \n",
    "            corpus = rp.col1\n",
    "            new_corpus = corpus.apply(lambda x: preprocess(x))\n",
    "\n",
    "            q_lis = []\n",
    "            for q in queries:\n",
    "                a = preprocess(q)\n",
    "                if len(a)>1:\n",
    "                    q_lis.append(a)\n",
    "            del queries\n",
    "\n",
    "            for i in range(len(q_lis)):\n",
    "                if cite_no[i] in gt:\n",
    "                    for j in gt[cite_no[i]]:\n",
    "                        if int(j) < len(new_corpus):\n",
    "                            pairs_lis.append(InputExample(texts=[q_lis[i],new_corpus[int(j)]],label=1.0)) #positive pairs\n",
    "                            pairs_lis.append(InputExample(texts=[q_lis[i],new_corpus[random.randint(0,len(new_corpus)-1)]],label=0.4)) #negative pairs\n",
    "                            pairs_lis.append(InputExample(texts=[q_lis[i],new_corpus[random.randint(0,len(new_corpus)-1)]],label=0.4))\n",
    "                            pairs_lis.append(InputExample(texts=[q_lis[i],new_corpus[random.randint(0,len(new_corpus)-1)]],label=0.4))\n",
    "            if (z!=0 and len(new_corpus)!=0 and len(new_corpus_prev)!=0):\n",
    "                pairs_lis.append(InputExample(texts = [new_corpus_prev[random.randint(0,len(new_corpus_prev)-1)],new_corpus[random.randint(0,len(new_corpus)-1)]],label=0.0))\n",
    "\n",
    "            new_corpus_prev = new_corpus\n",
    "        except:\n",
    "            print(\"eror in \",f)\n",
    "            new_corpus_prev = None\n",
    "    return pairs_lis\n",
    "\n",
    "    \n",
    "train_data = get_dataset(train_docs)\n",
    "# val_data = get_dataset(val_docs)\n",
    "test_data = get_dataset(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b03fcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define your train dataset, the dataloader and the train loss\n",
    "train_dataloader = DataLoader(train_data, shuffle=True, batch_size=16)\n",
    "# val_dataloader = DataLoader(val_data, shuffle=True, batch_size=16)\n",
    "test_dataloader = DataLoader(test_data, shuffle=True, batch_size=16)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e558f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00ca1f20217492d95df87ec84dc1d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/391 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff4d9af6063648d4831d644b06d385cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d82251ef55014d96975235c4a01a9652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65eb6aaef78b461aac582ade90eb9559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a9b10bda804f5a9bb9ff21541b7c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1202becc09548848b24c5b5cbb245eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "974db37e501d48a6921d7af86b7c5a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4607003aaf0547b391f4376df74ad713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74dae81b5532411f925fe6b1ef556669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16dfab72c81b4e34bdab9d62825ffc58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f71764caef4a0e83e29f569c704077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/399 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64ce8a0b07f4dc0b7bab9b99270ee39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d70af1855641c9ad60fe0ab3a294df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5306082eea5427db63c3b6b6127d316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027d9224cea847c495771949482e3b5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/4048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 10.76 GiB total capacity; 3.98 GiB already allocated; 17.56 MiB free; 4.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11978/2010031843.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCosineSimilarityLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#Tune the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_objectives\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/new/lib/python3.7/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[1;32m    703\u001b[0m                         \u001b[0mskip_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mscale_before_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                         \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m                         \u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/new/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/new/lib/python3.7/site-packages/sentence_transformers/losses/CosineSimilarityLoss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentence_features, labels)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence_embedding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence_feature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos_score_transformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/new/lib/python3.7/site-packages/sentence_transformers/losses/CosineSimilarityLoss.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence_embedding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence_feature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos_score_transformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/new/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/new/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/new/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/new/lib/python3.7/site-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mtrans_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0moutput_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrans_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0moutput_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/new/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/new/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m         )\n\u001b[1;32m   1008\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/new/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/new/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    588\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m                 )\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/new/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/new/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 512\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m         )\n\u001b[1;32m    514\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/new/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2360\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/new/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/new/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/new/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/new/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mgelu\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m   1554\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1556\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 10.76 GiB total capacity; 3.98 GiB already allocated; 17.56 MiB free; 4.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#Define the model. Either from scratch of by loading a pre-trained model\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "#Tune the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=2, warmup_steps=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc7d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(model,'bert_fine_tuned.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be4f1f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('distilbert_fine_tuned.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d0bc28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/tagucci/pythonrouge.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "826387fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ignite.metrics import Rouge  #https://pypi.org/project/pytorch-ignite/\n",
    "from rouge_score import rouge_scorer  #https://pypi.org/project/rouge-score/\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "from pythonrouge.pythonrouge import Pythonrouge\n",
    "\n",
    "\n",
    "def get_matching_sentences(model,corpus,queries,gt,cite_no):\n",
    "    #f1 score will be same as precision and recall in our case: since documents\n",
    "    \n",
    "    # Get a vector for each headline (sentence) in the corpus\n",
    "    corpus_embeddings = model.encode(corpus)\n",
    "    corpus_embeddings = corpus_embeddings/np.linalg.norm(corpus_embeddings,axis=0).reshape(-1)\n",
    "    # Define search queries and embed them to vectors as well\n",
    "\n",
    "    query_embeddings = model.encode(queries)\n",
    "    # For each search term return 3 closest sentences\n",
    "    closest_n = 3\n",
    "    total_nums_correct = 0\n",
    "    total_retrieved = 0\n",
    "    total_relevent = 0\n",
    "    rouge1 = []\n",
    "    rouge2 = []\n",
    "    rouge_su4 = []\n",
    "    for i in range(len(queries)):\n",
    "        query, query_embedding  = queries[i], query_embeddings[i]\n",
    "        distances = scipy.spatial.distance.cdist([query_embedding], corpus_embeddings, \"cosine\")[0]\n",
    "\n",
    "        results = zip(range(len(distances)), distances)\n",
    "        results = sorted(results, key=lambda x: x[1])\n",
    "\n",
    "#         print(\"\\n\\n======================\\n\\n\")\n",
    "#         print(\"Query:\", query)\n",
    "        indexes = results[0:closest_n]\n",
    "        top_n = []\n",
    "        for l,k in indexes:\n",
    "            top_n.append(l)\n",
    "        if cite_no[i] in gt:\n",
    "            nums_correct = len(np.intersect1d(top_n,gt[cite_no[i]]))\n",
    "            total_nums_correct += nums_correct\n",
    "            total_relevent += len(gt[cite_no[i]])\n",
    "            total_retrieved += 3\n",
    "        for idx, distance in results[0:closest_n]:\n",
    "            scores = scorer.score(corpus[idx].strip(), query)\n",
    "            rouge = Pythonrouge(summary_file_exist=False,\n",
    "                    summary=[[corpus[idx].strip()]], reference=[[[query]]],\n",
    "                    n_gram=2, ROUGE_SU4=True, ROUGE_L=False,\n",
    "                    recall_only=True, stemming=True, stopwords=True,\n",
    "                    word_level=True, length_limit=True, length=50,\n",
    "                    use_cf=False, cf=95, scoring_formula='average',\n",
    "                    resampling=True, samples=1000, favor=True, p=0.5)\n",
    "    \n",
    "            score = rouge.calc_score()\n",
    "            rouge1.append(score['ROUGE-1'])\n",
    "            rouge2.append(score['ROUGE-2'])\n",
    "            rouge_su4.append(score['ROUGE-SU4'])\n",
    "\n",
    "            \n",
    "    return total_nums_correct, total_relevent,total_retrieved, np.mean(rouge1), np.mean(rouge2), np.mean(rouge_su4)\n",
    "    \n",
    "                    \n",
    "#             print(corpus[idx].strip(), \"(Score: %.4f)\" % (1-distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1582ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2720388d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All arrays must be of the same length\n",
      "All arrays must be of the same length\n",
      "All arrays must be of the same length\n",
      "All arrays must be of the same length\n",
      "All arrays must be of the same length\n",
      "metrics obtained in train: recall 0.14919545669663986, precision 28.022222222222222, f1-score 0.29681063904907623, rouge1 0.17038241186460112, rouge2 0.03689185715650203, rouge_su4 0.05247251314530701\n"
     ]
    }
   ],
   "source": [
    "os.environ['TOKENIZERS_PARALLELISM']= '0'\n",
    "\n",
    "def evaluate(model,files):\n",
    "    gt_big = {}\n",
    "    corpus_big = {}\n",
    "    queries_big = {}\n",
    "    cite_no_big = {}\n",
    "    rouge1_lis = []\n",
    "    rouge2_lis = []\n",
    "    rouge_su4_lis = []\n",
    "    tp_big = 0\n",
    "    tot_relevent = 0\n",
    "    tot_retrieved = 0\n",
    "    for z,f in enumerate(files):\n",
    "        try:\n",
    "            citants = pd.read_json(\"From-ScisummNet-2019/\"+str(f)+\"/citing_sentences.json\")\n",
    "            citants = citants[['citance_No','clean_text']]\n",
    "            queries = list(citants['clean_text'])\n",
    "            cite_no = list(citants.citance_No)\n",
    "            tree = ET.parse(\"From-ScisummNet-2019/\"+f+\"/Reference_XML/\"+f+\".xml\")\n",
    "            root = tree.getroot()\n",
    "            final1=[]\n",
    "            final2=[]\n",
    "\n",
    "\n",
    "            i = 0\n",
    "            total = len(root)\n",
    "            for a in root:\n",
    "                for b in a:\n",
    "                    final1.append(b.text)\n",
    "                    if i == 0:\n",
    "                        final2.append(\"Abstract\")\n",
    "                    if i == 1:\n",
    "                        final2.append(\"Introduction\")\n",
    "                    elif i < total-2:\n",
    "                        final2.append(\"Experiment/Discussion\")\n",
    "                    if i == total-2 or i == total-1:\n",
    "                        final2.append(\"Results/Conclusion\")\n",
    "                    if i == total:\n",
    "                        final2.append(\"Acknowledgment\")\n",
    "                i = i+1\n",
    "\n",
    "            d={'col1':final1,'col2':final2}\n",
    "            rp = pd.DataFrame(data=d)\n",
    "            ann = \"From-ScisummNet-2019/\"+f+\"/annotation/\"+f+\".ann.txt\"\n",
    "            with open(ann,\"r\") as f:\n",
    "                data = f.read()\n",
    "            idx = {'Citance Number':0,'Reference Article':1,'Citing Article':2,'Citation Marker Offset':3,'Citation Marker':4,'Citation Offset':5,'Reference Offset':7}\n",
    "            gt = {}\n",
    "            lines = data.split('\\n')\n",
    "            for line in lines:\n",
    "                lis = line.split('|')\n",
    "                if len(lis)==11:\n",
    "                    cit_no = lis[0].split(':')[1]\n",
    "                    ref_off = lis[7].split(':')[1].strip()\n",
    "                    import ast\n",
    "                    ref_off = ast.literal_eval(ref_off)\n",
    "                    ref_off = list(map(int, ref_off))\n",
    "                    gt[int(cit_no)] = ref_off \n",
    "            corpus = rp.col1\n",
    "            new_corpus = corpus.apply(lambda x: preprocess(x))\n",
    "\n",
    "            q_lis = []\n",
    "            for q in queries:\n",
    "                a = preprocess(q)\n",
    "                if len(a)>1:\n",
    "                    q_lis.append(a)\n",
    "\n",
    "            if len(new_corpus)==0:\n",
    "                continue\n",
    "\n",
    "            tp, tot_rele,tot_retrieved, rouge1, rouge2, rouge_su4 = get_matching_sentences(model,new_corpus,q_lis,gt,cite_no)\n",
    "            tp_big += tp\n",
    "            tot_relevent += tot_rele\n",
    "            tot_retrieved += tot_retrieved\n",
    "\n",
    "            rouge1_lis.append(rouge1)\n",
    "            rouge2_lis.append(rouge2)\n",
    "            rouge_su4_lis.append(rouge_su4)\n",
    "        except Exception as e:\n",
    "            print(e, f)\n",
    "        \n",
    "    recall = tp_big/tot_relevent\n",
    "    precision = tp_big/tot_retrieved\n",
    "    f1 = 2*recall*precision/(recall+precision)\n",
    "    return recall,precision,f1, np.mean(rouge1_lis), np.mean(rouge2_lis), np.mean(rouge_su4_lis)\n",
    "    \n",
    "recall,precision,f1, rouge1, rouge2, rouge_su4 = evaluate(model,train_docs)   \n",
    "print(\"metrics obtained in train: recall {}, precision {}, f1-score {}, rouge1 {}, rouge2 {}, rouge_su4 {}\".format(recall,precision,f1, rouge1, rouge2, rouge_su4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4e60dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All arrays must be of the same length\n",
      "All arrays must be of the same length\n",
      "metrics obtained in train: recall 0.04483074107959744, precision 0.9607843137254902, f1-score 0.08566433566433565, rouge1 0.17457578815182143, rouge2 0.04132911100273701, rouge_su4 0.05485216044999575\n"
     ]
    }
   ],
   "source": [
    "recall,precision,f1, rouge1, rouge2, rouge_su4 = evaluate(model,val_docs)   \n",
    "print(\"metrics obtained in test: recall {}, precision {}, f1-score {}, rouge1 {}, rouge2 {}, rouge_su4 {}\".format(recall,precision,f1, rouge1, rouge2, rouge_su4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "173db4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71af1c9881f46389080aea29a128e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875b212ad7e64602ace0ef0b181fde19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.99k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ee21ab264048038f7bce8a8a9458f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/550 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611578028e1745f99543731b9ed13baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80eeb9507884e03a635d8974de386ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef8bd6177b24fd980771a91ce412cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6377cde9ff1418d8409e5dd1685acbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf93b7c56264e5e82ece426b295a6b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac870ecb28b6444cae14a7fd0721c496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e3e4b131114f4a91e2504c9e0d8af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/450 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d5a3bc4011460bafb0c51d1ca9ab47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b73f6e264044c90b03a798e2cc6b28b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#pre-trained model\n",
    "model_pt = SentenceTransformer('distilbert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1f7a93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All arrays must be of the same length\n",
      "All arrays must be of the same length\n",
      "metrics obtained in test: recall 0.039341262580054895, precision 0.8431372549019608, f1-score 0.07517482517482518, rouge1 0.14700679230736413, rouge2 0.03251376210700356, rouge_su4 0.046418343330599805\n"
     ]
    }
   ],
   "source": [
    "recall,precision,f1, rouge1, rouge2, rouge_su4 = evaluate(model_pt,val_docs)   \n",
    "print(\"metrics obtained in test: recall {}, precision {}, f1-score {}, rouge1 {}, rouge2 {}, rouge_su4 {}\".format(recall,precision,f1, rouge1, rouge2, rouge_su4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
